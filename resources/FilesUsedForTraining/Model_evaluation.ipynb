{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUHwHA7PGYO3"
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUmcE9F-sz80"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "SGM8rNu9uFng",
    "outputId": "841dfc0e-396b-4739-c679-8bde84d7bcb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "import sys\n",
    "root_path = '/content/gdrive/My Drive/MasterSapienza/Semestre2/NLP/HM1/Arci/'  #change dir to your project folder\n",
    "sys.path.insert(0, root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxUvmBXkwghI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, TimeDistributed, concatenate, Activation, Masking\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import os, datetime, time\n",
    "\n",
    "# Custom packages\n",
    "import ChinesePreprocess as CP\n",
    "import ModelConfiguration as ModelConfig\n",
    "import TrainingUtils\n",
    "from code_provided.score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lb380TnZuOJL"
   },
   "outputs": [],
   "source": [
    "def load_defaults(trainds=\"msr_training_simp_reordered\", testds=\"msr_test_gold_simp_reordered\", maxlength = 50, vocab_path = \"vocab_msr\", verbose=False):\n",
    "  print(\"Loading configurations.\")\n",
    "  print(\"Training dataset: \", trainds)\n",
    "  print(\"Testing dataset: \", testds)\n",
    "  print(\"Vocabulary: \", vocab_path)\n",
    "  print(\"maxlength: \", maxlength)\n",
    "  \n",
    "  print(\"\\n******************** Loading vocabulary **********************\\n\")\n",
    "  with open(root_path + \"../vocabs/%s.pkl\" % vocab_path,'rb') as voc:\n",
    "    vocab = pickle.load(voc)\n",
    "    print(\"Vocabulary loaded.\")\n",
    "  \n",
    "  print(\"\\n******************** Extract train data (MSR) **********************\\n\")\n",
    "  ds_train = CP.ChinesePreprocess(root_path + \"../dataset/icwb2-data/training/%s.utf8\" % trainds, \n",
    "                                  num_samples=0, # Should be zero mostly. Becasue it's convenient to read everything most of the times. If not zero, some words to build the vocabulary might get lost in the trimming\n",
    "                                  vocabulary = vocab, # Static preset vocabulary. Same in training\n",
    "                                  verbose=False)\n",
    "\n",
    "  print(\"\\n\\n******************** Extract test data (MSR) *******************\\n\")\n",
    "  ds_test = CP.ChinesePreprocess(root_path + \"../dataset/icwb2-data/gold/%s.utf8\" % testds, \n",
    "                                 num_samples=0, \n",
    "                                 vocabulary = vocab,# Same vocabulary of training\n",
    "                                 verbose=False)\n",
    "\n",
    "    # Maximum length for padding\n",
    "  train = CP.ChinesePreprocess.apply_padding_data_and_labels(ds_train, maxlength, False)\n",
    "  test = CP.ChinesePreprocess.apply_padding_data_and_labels(ds_test, maxlength, False)\n",
    "  print(\"Done.\")\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhUdW8KS9uHs"
   },
   "source": [
    "## Score function (Provided by professor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OwbHZxPj9yhv",
    "outputId": "7d68230b-a89c-4d93-d561-909f4bbbd712"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_iter = [\"BEBESBIIE\",\"BIIIEBEBESS\"]\n",
    "gold_iter = [\"BEBIEBIES\",\"BIIESBEBESS\"]\n",
    "score(pred_iter, gold_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lunf9kmVO0nO"
   },
   "source": [
    "##### Manual test (not done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iqF9tcw5igR"
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n",
    "rec = tf.keras.metrics.Recall()\n",
    "pre = tf.keras.metrics.Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "WyAvK3XJ2p6y",
    "outputId": "b308779d-7d90-493b-c8e8-0952a9c66a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Final result:  0.8333333\n"
     ]
    }
   ],
   "source": [
    "##sess = tf.Session()\n",
    "m = tf.keras.metrics.Recall()\n",
    "m.update_state([[0, 1, 1, 1],[0, 1, 1, 1]], [[0, 1, 1, 1],[1, 0, 1, 1]])\n",
    "print('Final result: ', m.result().numpy())  # Final result: 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcMq0bNsAQKV"
   },
   "source": [
    "## Util methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzVEEsk6PflT"
   },
   "outputs": [],
   "source": [
    "# For model evaluation\n",
    "\n",
    "def num2BIES(sent):\n",
    "  #''.join(num2BIES(['0', '2', '0', '2', '3', '3', '0', '2', '0', '2', '3', '0', '2']))\n",
    "  #Out: BEBESSBEBESBE\n",
    "  tags = {'0':'B',\n",
    "          '1':'I',\n",
    "          '2':'E',\n",
    "          '3':'S'\n",
    "         }\n",
    "  bies = [tags[s] for s in sent]\n",
    "  return bies\n",
    "\n",
    "def readableBIES(sent):\n",
    "  #readableBIES('BEBESSBEBESBE')\n",
    "  #out: ['BE', 'BE', 'S', 'S', 'BE', 'BE', 'S', 'BE']\n",
    "  bies = []\n",
    "  word = []\n",
    "  cut = False\n",
    "  for i in sent:\n",
    "    word.append(i)\n",
    "    if i == 'B' or i == 'I': \n",
    "      if cut: \n",
    "        bies.append(''.join(word))\n",
    "        word = []\n",
    "      cut = True \n",
    "    if i == 'E':\n",
    "      bies.append(''.join(word))\n",
    "      word = []\n",
    "      cut=False\n",
    "    if i == 'S':\n",
    "      bies.append(''.join(word))\n",
    "      word = []\n",
    "      cut=False\n",
    "  return bies\n",
    "\n",
    "def printComparisonSingle(ypred,k, useTest=False, table=False):\n",
    "  if not useTest:\n",
    "    length = len(train.sents_nospaces[k])\n",
    "    print(\"Length of the sequence: \", str(len(train.sents_nospaces[k])))\n",
    "    print(\"Input of network:\\n\\n\",train.unigrams_pad[k],'\\n')\n",
    "    print(\"GroundT:\",train.labels_bies[k])\n",
    "    y0 = [str(np.argmax(i)) for i in ypred[k]]\n",
    "    print(\"Output:\\t\" , y0[:length])\n",
    "    biesy = num2BIES(y0[:length])\n",
    "    if table:\n",
    "      print(tabulate([[\"Test\"] + train.sents_split[k].replace('  ',' ').split(' '), \n",
    "                     [\"Output\"] + readableBIES(biesy)]))\n",
    "    else:\n",
    "      print(\"Test: \\t\", train.sents_split[k].replace('  ',' '))\n",
    "      print(\"BIES: \\t\", ''.join(biesy))\n",
    "  if useTest:\n",
    "    length = len(test.sents_nospaces[k])\n",
    "    print(\"Length of the sequence: \", str(len(test.sents_nospaces[k])))\n",
    "    print(\"Input of network:\\n\\n\", test.unigrams_pad[k],'\\n')\n",
    "    print(\"GroundT:\",test.labels_bies[k])\n",
    "    y0 = [str(np.argmax(i)) for i in ypred[k]]\n",
    "    print(\"Output:\\t\" , y0[:length])\n",
    "    biesy = num2BIES(y0[:length])\n",
    "    if table:\n",
    "      print(tabulate([[\"Test\"] + test.sents_split[k].replace('  ',' ').split(' '), \n",
    "                     [\"Output\"] + readableBIES(biesy)]))\n",
    "    else:\n",
    "      print(\"Test: \\t\", test.sents_split[k].replace('  ',' '))\n",
    "      print(\"BIES: \\t\", ''.join(biesy))\n",
    "  ygroundbies = num2BIES(test.labels_bies[k])\n",
    "  return y0, biesy, ygroundbies  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHKW8mkFxnA4"
   },
   "source": [
    "# Metrics analysis. \n",
    "Find the right metric to evaluate your model.\n",
    "In addition, convert your samples to readable understandable sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "JwfcDGPi1J_r",
    "outputId": "8684d37b-a25c-459f-df66-6c4adb3ef2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "model = load_model(root_path + '../models/2019-04-22_GPU_Model9_VocabSmall_model.h5')\n",
    "#\"content/gdrive/My Drive/MasterSapienza/Semestre2/NLP/HM1/models/2019-04-22_TPU_Model7_FullVocab_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "FV5PPdFD52VD",
    "outputId": "fec83bd1-c1d3-4a29-e176-2c9f583b0b33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 50, 64)       27633856    input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 50, 64)       27633856    input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 50, 128)      0           embedding_8[0][0]                \n",
      "                                                                 embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 50, 512)      788480      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 50, 4)        2052        bidirectional_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 56,058,244\n",
      "Trainable params: 56,058,244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1VnKQYY3AU9F"
   },
   "source": [
    "### Test from samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STXGxR7_2b1A"
   },
   "outputs": [],
   "source": [
    "k=0; j=16 # Range of samples to perform the experiment\n",
    "xin = [test.unigrams_pad[k:j],test.bigrams_pad[k:j]]\n",
    "yout = test.labels[k:j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whlANsgQtnND"
   },
   "outputs": [],
   "source": [
    "#k=0; j=16 # Range of samples to perform the experiment\n",
    "#xin = [test.unigrams_pad,test.bigrams_pad]\n",
    "#yout = test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "Rb7JOrRG9leY",
    "outputId": "884f1d64-1aeb-4d65-a0f7-6fc8f0660ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "16/16 [==============================] - 1s 66ms/sample - loss: 0.1368 - acc: 0.9754 - recall_4: 0.9754 - precision_4: 0.9754\n",
      "Length of the sequence:  48\n",
      "Input of network:\n",
      "\n",
      " [336837 315609 138195 311174 363741 424986 129629 184437 393533 162297\n",
      " 344685 204985 205336 335882 178139 354959  29769 253125  57660   8281\n",
      " 427730 336837 315609 425331 195252  72974 291134 125414 424986 219356\n",
      "   9223 292032 224022 177908 204985 336837 315609  24921 229145 424986\n",
      " 344685 204985 159824  72974 210589  30893 424986   9223      0      0] \n",
      "\n",
      "GroundT: ['0', '1', '2', '0', '2', '3', '3', '0', '2', '3', '3', '3', '0', '1', '1', '2', '0', '2', '3', '0', '2', '0', '1', '1', '2', '3', '0', '2', '3', '3', '3', '0', '2', '3', '3', '0', '2', '0', '2', '3', '3', '3', '3', '3', '0', '2', '3', '3']\n",
      "Output:\t ['0', '1', '2', '0', '2', '3', '3', '0', '2', '3', '3', '3', '0', '1', '1', '2', '1', '2', '3', '0', '2', '0', '1', '1', '2', '3', '0', '2', '3', '3', '3', '0', '2', '3', '3', '0', '2', '0', '2', '3', '3', '3', '3', '3', '0', '2', '3', '3']\n",
      "Test: \t 社会学 概论 》 （ 合编 ） 、 《 经济体制 改革 对 农村 社会关系 的 影响 》 等 。 译着 有 《 社会 管理 》 、 《 人 的 前景 》 。\n",
      "BIES: \t BIEBESSBESSSBIIEIESBEBIIESBESSSBESSBEBESSSSSBESS\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x=xin,y=yout)\n",
    "ypred = model.predict(x=xin)\n",
    "\n",
    "sample = 10\n",
    "y0 = printComparison(ypred,sample, useTest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "3y72GJuit4pL",
    "outputId": "4b4be1ff-78cf-4446-c00e-18942a84f7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the sequence:  48\n",
      "Input of network:\n",
      "\n",
      " [336837 315609 138195 311174 363741 424986 129629 184437 393533 162297\n",
      " 344685 204985 205336 335882 178139 354959  29769 253125  57660   8281\n",
      " 427730 336837 315609 425331 195252  72974 291134 125414 424986 219356\n",
      "   9223 292032 224022 177908 204985 336837 315609  24921 229145 424986\n",
      " 344685 204985 159824  72974 210589  30893 424986   9223      0      0] \n",
      "\n",
      "GroundT: ['0', '1', '2', '0', '2', '3', '3', '0', '2', '3', '3', '3', '0', '1', '1', '2', '0', '2', '3', '0', '2', '0', '1', '1', '2', '3', '0', '2', '3', '3', '3', '0', '2', '3', '3', '0', '2', '0', '2', '3', '3', '3', '3', '3', '0', '2', '3', '3']\n",
      "Output:\t ['0', '1', '2', '0', '2', '3', '3', '0', '2', '3', '3', '3', '0', '1', '1', '2', '1', '2', '3', '0', '2', '0', '1', '1', '2', '3', '0', '2', '3', '3', '3', '0', '2', '3', '3', '0', '2', '0', '2', '3', '3', '3', '3', '3', '0', '2', '3', '3']\n",
      "Test: \t 社会学 概论 》 （ 合编 ） 、 《 经济体制 改革 对 农村 社会关系 的 影响 》 等 。 译着 有 《 社会 管理 》 、 《 人 的 前景 》 。\n",
      "BIES: \t BIEBESSBESSSBIIEIESBEBIIESBESSSBESSBEBESSSSSBESS\n",
      "['B', 'I', 'E', 'B', 'E', 'S', 'S', 'B', 'E', 'S', 'S', 'S', 'B', 'I', 'I', 'E', 'B', 'E', 'S', 'B', 'E', 'B', 'I', 'I', 'E', 'S', 'B', 'E', 'S', 'S', 'S', 'B', 'E', 'S', 'S', 'B', 'E', 'B', 'E', 'S', 'S', 'S', 'S', 'S', 'B', 'E', 'S', 'S']\n",
      "['B', 'I', 'E', 'B', 'E', 'S', 'S', 'B', 'E', 'S', 'S', 'S', 'B', 'I', 'I', 'E', 'I', 'E', 'S', 'B', 'E', 'B', 'I', 'I', 'E', 'S', 'B', 'E', 'S', 'S', 'S', 'B', 'E', 'S', 'S', 'B', 'E', 'B', 'E', 'S', 'S', 'S', 'S', 'S', 'B', 'E', 'S', 'S']\n",
      "Score:  0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "sample = 10\n",
    "y0, ybies, ygroundbies = printComparison(ypred,sample, useTest=True)\n",
    "print(ygroundbies)\n",
    "print(ybies)\n",
    "print(\"Score: \", score([ybies],[ygroundbies]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8O1MD0GFW6e"
   },
   "source": [
    "## Experiment with whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n1XA-Rl0Faw7",
    "outputId": "d81d0d11-a450-4168-d7c5-a34507379602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999/9999 [==============================] - 68s 7ms/sample - loss: 5.9467 - acc: 0.2897 - recall: 0.2865 - precision: 0.2898\n"
     ]
    }
   ],
   "source": [
    "k=1\n",
    "j=10000\n",
    "#print(\"Length of the sequence: \", str(len(train.sents_nospaces[k])))\n",
    "#print(train.sents_split[k:j]) # No. 4 has unigrams and bigrams\n",
    "#print(train.unigrams_pad[k:j])\n",
    "#print(train.labels_bies[k:j])\n",
    "#print(train.labels[k:j])\n",
    "xin = [train.unigrams_pad[k:j],train.bigrams_pad[k:j]]\n",
    "yout = train.labels[k:j]\n",
    "\n",
    "model.evaluate(x=xin,y=yout)\n",
    "ypred = model.predict(x=xin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "wgyUPT6UF956",
    "outputId": "6fc1ae39-11b8-40a0-dc5a-769c6e7b5cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the sequence:  19\n",
      "“  这  首先  是  个  民族  问题  ，  民族  的  感情  问题  。\n",
      "[113514 125267 328492 153491 218963 196714 210292 306428 208114  25420\n",
      "  22849 210292 306428 359023 286835  41305 208114  25420 350214      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n",
      "['3', '3', '0', '2', '3', '3', '0', '2', '0', '2', '3', '0', '2', '3', '0', '2', '0', '2', '3']\n",
      "['3', '3', '3', '0', '2', '3', '3', '0', '2', '3', '3', '3', '2', '0', '2', '3', '3', '3', '0']\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "y0 = [str(np.argmax(i)) for i in ypred[5]]\n",
    "print(\"Length of the sequence: \", str(len(train.sents_nospaces[k])))\n",
    "print(train.sents_split[k]) # No. 4 has unigrams and bigrams\n",
    "print(train.unigrams_pad[k])\n",
    "print(train.labels_bies[k])\n",
    "print(y0[:len(train.sents_nospaces[k])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xX2D65s3zaVY"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "884mxYBYzfcH"
   },
   "source": [
    "## Model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "by01nuLXzeov",
    "outputId": "e4aeae42-5e96-4b2f-f6a9-ad5d32afc76e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configurations.\n",
      "Training dataset:  msr_training_simp_reordered\n",
      "Testing dataset:  msr_test_gold\n",
      "Vocabulary:  vocab_msr\n",
      "maxlength:  50\n",
      "\n",
      "******************** Loading vocabulary **********************\n",
      "\n",
      "Vocabulary loaded.\n",
      "\n",
      "******************** Extract train data (MSR) **********************\n",
      "\n",
      "[INFO] Using preset vocabulary. No. of elements:  431779\n",
      "\n",
      "\n",
      "******************** Extract test data (MSR) *******************\n",
      "\n",
      "[INFO] Using preset vocabulary. No. of elements:  431779\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train, test = load_defaults(testds=\"msr_test_gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "6zrPdrSm4b-B",
    "outputId": "09e5b817-98a5-4359-fa36-c7d018d1ea16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(root_path + '../models/2019-04-22_GPU_Model9_VocabSmall_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZVUPPgn3a_t"
   },
   "outputs": [],
   "source": [
    "k=0; j=10 # Range of samples to perform the experiment\n",
    "xin = [test.unigrams_pad[k:j],test.bigrams_pad[k:j]]\n",
    "yout = test.labels[k:j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KArhy0ge3a_v"
   },
   "outputs": [],
   "source": [
    "#k=0; j=16 # Range of samples to perform the experiment\n",
    "#xin = [test.unigrams_pad,test.bigrams_pad]\n",
    "#yout = test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "fvV7h9iV3a_x",
    "outputId": "21b81c36-aa8f-4188-dc62-71a2116331f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "10/10 [==============================] - 0s 9ms/sample - loss: 0.2497 - acc: 0.9602 - recall_4: 0.9602 - precision_4: 0.9602\n",
      "Length of the sequence:  13\n",
      "Input of network:\n",
      "\n",
      " [426562  18862 246646 342376 382542 187757  68038 316411 184437 122544\n",
      "  72974 161561 306922      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0] \n",
      "\n",
      "GroundT: ['0', '2', '0', '2', '3', '3', '0', '2', '0', '2', '3', '0', '2']\n",
      "Output:\t ['0', '2', '0', '2', '3', '3', '0', '2', '0', '2', '3', '0', '3']\n",
      "Test: \t 扬帆 远东 做 与 中国 合作 的 先行 \n",
      "BIES: \t BEBESSBEBESBS\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x=xin,y=yout)\n",
    "ypred = model.predict(x=xin)\n",
    "\n",
    "sample = 0\n",
    "y0 = printComparison(ypred,sample, useTest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "j4FRYUFn4rmO",
    "outputId": "37119d4f-236b-4e77-df23-ff1676c53e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 11, 24, 31, 30, 25, 35, 15, 9, 18]\n",
      "[13, 11, 24, 31, 30, 25, 35, 15, 9, 18]\n"
     ]
    }
   ],
   "source": [
    "def format_prediction(ypred):\n",
    "  ypredf = [] # Predicted output (formatted)\n",
    "  for y in ypred:\n",
    "    ypredf.append([str(np.argmax(i)) for i in y])\n",
    "  #print(ypredf)\n",
    "  ybies = [''.join(num2BIES(y)[:len(test.sents_nospaces[i])]) for i,y in enumerate(ypredf)]\n",
    "  return ybies\n",
    "\n",
    "# Length of the output is the same\n",
    "\n",
    "print([len(x) for x in format_prediction(ypred)])\n",
    "print([len(x) for x in test.sents_nospaces[k:j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76mnoxr_Emai"
   },
   "outputs": [],
   "source": [
    "yground = [ ''.join(num2BIES(y)) for y in test.labels_bies[0:10] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "loE4a6BiFOmQ",
    "outputId": "f04144b2-0396-483e-d73d-8d9ac4f6a35d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEBESSBEBESBE',\n",
       " 'BESBEBESBES',\n",
       " 'BESBEBESSSSBESSBEBESBIES',\n",
       " 'BEBESBEBEBEBESBEBIIESBIEBEBEBES',\n",
       " 'BIESSSBEBEBEBESBESBEBEBESBEBES',\n",
       " 'BIESSBIIESBEBEBEBESBESBES',\n",
       " 'BIIESBESSBIESSBESBESBESSBIESBEBEBES',\n",
       " 'SBESSBEBEBESBES',\n",
       " 'SSSBIEBES',\n",
       " 'SBEBESBEBIESSSSBES']"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eSj7AvJ1Egwu",
    "outputId": "d66d4d57-e974-4eec-8ddd-882481c61ebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.957345971563981\n"
     ]
    }
   ],
   "source": [
    "print(\"Score: \", score(format_prediction(ypred),yground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "JJD_yA1O3a_1",
    "outputId": "4b4be1ff-78cf-4446-c00e-18942a84f7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the sequence:  48\n",
      "Input of network:\n",
      "\n",
      " [336837 315609 138195 311174 363741 424986 129629 184437 393533 162297\n",
      " 344685 204985 205336 335882 178139 354959  29769 253125  57660   8281\n",
      " 427730 336837 315609 425331 195252  72974 291134 125414 424986 219356\n",
      "   9223 292032 224022 177908 204985 336837 315609  24921 229145 424986\n",
      " 344685 204985 159824  72974 210589  30893 424986   9223      0      0] \n",
      "\n",
      "GroundT: ['0', '1', '2', '0', '2', '3', '3', '0', '2', '3', '3', '3', '0', '1', '1', '2', '0', '2', '3', '0', '2', '0', '1', '1', '2', '3', '0', '2', '3', '3', '3', '0', '2', '3', '3', '0', '2', '0', '2', '3', '3', '3', '3', '3', '0', '2', '3', '3']\n",
      "Output:\t ['0', '1', '2', '0', '2', '3', '3', '0', '2', '3', '3', '3', '0', '1', '1', '2', '1', '2', '3', '0', '2', '0', '1', '1', '2', '3', '0', '2', '3', '3', '3', '0', '2', '3', '3', '0', '2', '0', '2', '3', '3', '3', '3', '3', '0', '2', '3', '3']\n",
      "Test: \t 社会学 概论 》 （ 合编 ） 、 《 经济体制 改革 对 农村 社会关系 的 影响 》 等 。 译着 有 《 社会 管理 》 、 《 人 的 前景 》 。\n",
      "BIES: \t BIEBESSBESSSBIIEIESBEBIIESBESSSBESSBEBESSSSSBESS\n",
      "['B', 'I', 'E', 'B', 'E', 'S', 'S', 'B', 'E', 'S', 'S', 'S', 'B', 'I', 'I', 'E', 'B', 'E', 'S', 'B', 'E', 'B', 'I', 'I', 'E', 'S', 'B', 'E', 'S', 'S', 'S', 'B', 'E', 'S', 'S', 'B', 'E', 'B', 'E', 'S', 'S', 'S', 'S', 'S', 'B', 'E', 'S', 'S']\n",
      "['B', 'I', 'E', 'B', 'E', 'S', 'S', 'B', 'E', 'S', 'S', 'S', 'B', 'I', 'I', 'E', 'I', 'E', 'S', 'B', 'E', 'B', 'I', 'I', 'E', 'S', 'B', 'E', 'S', 'S', 'S', 'B', 'E', 'S', 'S', 'B', 'E', 'B', 'E', 'S', 'S', 'S', 'S', 'S', 'B', 'E', 'S', 'S']\n",
      "Score:  0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "sample = 10\n",
    "y0, ybies, ygroundbies = printComparisonSingle(ypred,sample, useTest=True)\n",
    "print(ygroundbies)\n",
    "print(ybies)\n",
    "print(\"Score: \", score([ybies],[ygroundbies]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6j2rbdfDtnP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtHLUN26WKZT"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GWh35anjWJdi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AvGabM6jwqeK"
   },
   "source": [
    "# Generate BIES file from Gold file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "sd9DRmNVwwEq",
    "outputId": "b652940f-cc6e-4011-8ee9-170f4bb9ad2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MAIN] Data preprocessing  starting...\n",
      "\n",
      "[INFO] Reading data file...\n",
      "[INFO] Read file: /content/gdrive/My Drive/MasterSapienza/Semestre2/NLP/HM1/Arci/../dataset/icwb2-data/gold/pku_test_gold.utf8\n",
      "[INFO] Total number of sentences:  1945\n",
      "[INFO] Sample of the file: \n",
      " ['（  二○○○年  十二月  三十一日  ）  （  附  图片  1  张  ）  ', '女士  们  ，  先生  们  ，  同志  们  ，  朋友  们  ：  '] \n",
      "\n",
      "\n",
      "[MAIN] Processing sentences into unigrams and bigrams with padding...\n",
      "[INFO] Converting to unigrams...\n",
      "[INFO] Converting to bigrams...\n",
      "\n",
      "[INFO] Generating vocabulary from sentence...\n",
      "[INFO] Vocabulary generated from sentence successfully. \n",
      " Number of elements: 59386\n",
      "[INFO]Sample of vocabulary: \n",
      "\n",
      "UNK : 1\n",
      "应资 : 2\n",
      "改〈 : 3\n",
      "务机 : 4\n",
      "任在 : 5\n",
      "[INFO] Conversion to translated sentences with vocabulary complete.\n",
      "--- Check: ---\n",
      "Element:  1\n",
      "Returned element: \n",
      " [11750, 45342, 9278, 9278, 9278, 24479, 43800, 45342, 42946, 19175, 43800, 54949, 26372, 46308, 11750, 58710, 46027, 23140, 2589, 53440, 46308]\n",
      "Converted using inverse vocabulary:\n",
      " ['（', '二', '○', '○', '○', '年', '十', '二', '月', '三', '十', '一', '日', '）', '（', '附', '图', '片', '1', '张', '）']\n",
      "Original element:\n",
      " ['（', '二', '○', '○', '○', '年', '十', '二', '月', '三', '十', '一', '日', '）', '（', '附', '图', '片', '1', '张', '）'] \n",
      "\n",
      "\n",
      "[INFO] Conversion to translated sentences with vocabulary complete.\n",
      "--- Check: ---\n",
      "Element:  1\n",
      "Returned element: \n",
      " [38825, 1105, 24461, 24461, 12626, 27551, 51621, 58615, 39392, 17523, 35426, 29286, 813, 43892, 28607, 54258, 23200, 58347, 19981, 40115]\n",
      "Converted using inverse vocabulary:\n",
      " ['（二', '二○', '○○', '○○', '○年', '年十', '十二', '二月', '月三', '三十', '十一', '一日', '日）', '）（', '（附', '附图', '图片', '片1', '1张', '张）']\n",
      "Original element:\n",
      " ['（二', '二○', '○○', '○○', '○年', '年十', '十二', '二月', '月三', '三十', '十一', '一日', '日）', '）（', '（附', '附图', '图片', '片1', '1张', '张）'] \n",
      "\n",
      "\n",
      "\n",
      "[MAIN] Processing the generation of labels...\n",
      "\n",
      "[INFO] Converting sentences to BIES format\n",
      "\n",
      "[MAIN] Data preprocessing finished successfully. Padding and one-hot encoding pending for training.\n"
     ]
    }
   ],
   "source": [
    "data = CP.ChinesePreprocess(root_path+'../dataset/icwb2-data/gold/pku_test_gold.utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOkt1M2tymW5"
   },
   "outputs": [],
   "source": [
    "data.labels_bies\n",
    "yground = [ ''.join(num2BIES(y)) for y in data.labels_bies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ja89DbOXy0qJ"
   },
   "outputs": [],
   "source": [
    "yground\n",
    "## save groundTruth file\n",
    "with open(root_path+'../dataset/icwb2-data/gold/pku_test_gold_BIES.utf8','w', encoding='utf-8') as file:\n",
    "  file.writelines('\\n'.join(yground))\n",
    "print(yground)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "lunf9kmVO0nO",
    "n8O1MD0GFW6e"
   ],
   "name": "Model evaluation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
